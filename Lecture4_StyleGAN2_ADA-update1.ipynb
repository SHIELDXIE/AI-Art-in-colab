{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHIELDXIE/stylegan2-train-colab/blob/main/Lecture4_StyleGAN2_ADA-update1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG7ZEc_982io"
      },
      "source": [
        "# StyleGAN2-ADA-PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj4PG4_i9Alt"
      },
      "source": [
        "## 0.1 环境搭建"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNBq2JTAs_pJ",
        "outputId": "33ec6f1f-29f6-4d5a-cf2a-d9836f524e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGEXPcFJ9UTY"
      },
      "source": [
        "查看分配到的GPU，如果分配到P100基本就够用了，V100更好。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VVICTCvd4mc",
        "outputId": "d245e44c-c95f-4913-8651-b934a53f093e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-b8077889-aa54-249a-f71d-f7db84a76450)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTjVmfSK9CYa"
      },
      "source": [
        "##1.1 安装代码库\n",
        "\n",
        "下一个单元格将会安装styleGAN2-ada的代码库（一个文件夹）到你的GoogleDrive里。网页版GoogleDrive里会在AI文件夹下看到新建的stylegan2-ada-pytorch文件夹。\n",
        "\n",
        "如果你已经安装过了，当前运行路径会移动到文件夹里。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8ADVNpBh8Ox",
        "outputId": "d18d57c6-9860-4e67-9797-5829b8645ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI/stylegan2-ada-pytorch\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 26.0 MB/s \n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.4.2-py3-none-any.whl (17 kB)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.2.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, opensimplex, ninja\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed ninja-1.10.2.3 opensimplex-0.4.2 torch-1.7.1 torchvision-0.8.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/AI/stylegan2-ada-pytorch\"):\n",
        "    %cd \"/content/drive/MyDrive/AI/stylegan2-ada-pytorch\"\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir AI\n",
        "    %cd AI\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    !mkdir result\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n",
        "else:\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    !mkdir result\n",
        "    %cd pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU\n",
        "    %cd ../\n",
        "\n",
        "!pip install ninja opensimplex torch==1.7.1 torchvision==0.8.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jMmUpn4DWRe"
      },
      "source": [
        "下面单元格是非必须运行的。其作用是更新代码库到原作者最新的版本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV9bdvzeDRPd"
      },
      "outputs": [],
      "source": [
        "# %cd \"/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "# !git config --global user.name \"test\"\n",
        "# !git config --global user.email \"test@test.com\"\n",
        "# !git fetch origin\n",
        "# !git pull\n",
        "# !git stash\n",
        "# !git checkout origin/main -- train.py generate.py legacy.py closed_form_factorization.py flesh_digression.py apply_factor.py README.md calc_metrics.py training/stylegan2_multi.py training/training_loop.py util/utilgan.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyCK9nLsEFrC"
      },
      "source": [
        "个人习惯，重新检查一遍当前路径是否正确。\n",
        "\n",
        "此时你应该看到 ....../stylegan2-ada-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN__6KEHdRL4",
        "outputId": "f3bde49c-5d92-43b9-a12f-4c0d37781aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZkcJ58P97Ls"
      },
      "source": [
        "##1.1 数据集准备\n",
        "\n",
        "图片的批量处理建议使用软件XnViewMP。\n",
        "\n",
        "上传由方形图片(512px或者1024px)组成的数据集，并且压缩成一个**.zip**文件。\n",
        "\n",
        "在电脑压缩完成之后上传到网页版本的GoogleDrive，具体路径是**AI/stylegan2-ada-pytorch/datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B-h6FpB9FaK"
      },
      "source": [
        "##1.2 训练模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNc-3wTO-MUd"
      },
      "source": [
        "以下是你在训练模型前需要设置的参数。但是许多都已经设置好了默认值，无需更改。\n",
        "\n",
        "比较重要的几个参数如下，\n",
        "* `dataset_path`: 数据集.zip的具体路径。可以通过侧边栏右键获得。\n",
        "* `resume_from`: 如果你是训练一个全新的数据集，作者建议使用 `'ffhq1024'` 或者 `'./pretrained/wikiart.pkl'` 进行迁移学习。（需要保证你的数据集和模型中训练的数据集图片大小一致）\n",
        "* `mirror_x` 和 `mirror_y`: 是否在水平方向和竖直方向作数据集图片的对称。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV0W6yxP-UIn"
      },
      "outputs": [],
      "source": [
        "#required: definitely edit these!\n",
        "dataset_path = 'datasets/dataset.zip'\n",
        "resume_from =   '/content/drive/MyDrive/AI/stylegan2-ada-pytorch/result/abstract_animal/00007-dataset-mirror-paper512-gamma50-bgc-resumeffhq512/network-snapshot-000000.pkl' #'../../pretrained_model/liquid_art-512.pkl' \n",
        "outdir = 'result/abstract_animal'    \n",
        "aug_strength = 2\n",
        "train_count = 0\n",
        "mirror_x = True\n",
        "mirror_y = False\n",
        "\n",
        "#optional: you might not need to edit these\n",
        "gamma_value = 50.0\n",
        "augs = 'bgc'#或者bgc\n",
        "# 'blit', 'geom', 'color', 'filter', 'noise', 'cutout', 'bg', 'bgc', 'bgcf', 'bgcfn', 'bgcfnc'\n",
        "config = 'paper512'\n",
        "#'auto', '11gb-gpu', '11gb-gpu-complex', '24gb-gpu', '24gb-gpu-complex', '48gb-gpu', '48gb-2gpu', 'stylegan2', 'paper256', 'paper512', 'paper1024', 'cifar', 'cifarbaseline', 'aydao'\n",
        "snapshot_count = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL-M7WnnfMDI",
        "outputId": "9ba5c56d-f91c-4241-c5a6-4e3c2d2efcb8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 2,\n",
            "  \"network_snapshot_ticks\": 2,\n",
            "  \"metrics\": [],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"datasets/dataset.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 2490,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 512\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 32768,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 8\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 50.0\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 64,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"ema_kimg\": 20,\n",
            "  \"ema_rampup\": null,\n",
            "  \"nimg\": 0,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_p\": 2.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/AI/stylegan2-ada-pytorch/result/abstract_animal/00007-dataset-mirror-paper512-gamma50-bgc-resumeffhq512/network-snapshot-000000.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"result/abstract_animal/00008-dataset-mirror-paper512-gamma50-bgc-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   result/abstract_animal/00008-dataset-mirror-paper512-gamma50-bgc-resumecustom\n",
            "Training data:      datasets/dataset.zip\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   2490\n",
            "Image resolution:   512\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  4980\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "starting G epochs:  0.0\n",
            "Resuming from \"/content/drive/MyDrive/AI/stylegan2-ada-pytorch/result/abstract_animal/00007-dataset-mirror-paper512-gamma50-bgc-resumeffhq512/network-snapshot-000000.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape        Datatype\n",
            "---                   ---         ---      ---                 ---     \n",
            "mapping.fc0           262656      -        [8, 512]            float32 \n",
            "mapping.fc1           262656      -        [8, 512]            float32 \n",
            "mapping.fc2           262656      -        [8, 512]            float32 \n",
            "mapping.fc3           262656      -        [8, 512]            float32 \n",
            "mapping.fc4           262656      -        [8, 512]            float32 \n",
            "mapping.fc5           262656      -        [8, 512]            float32 \n",
            "mapping.fc6           262656      -        [8, 512]            float32 \n",
            "mapping.fc7           262656      -        [8, 512]            float32 \n",
            "mapping               -           512      [8, 16, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [8, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [8, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [8, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [8, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [8, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [8, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [8, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [8, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [8, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [8, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [8, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [8, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [8, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [8, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [8, 512, 32, 32]    float32 \n",
            "synthesis.b32.conv1   2622465     1040     [8, 512, 32, 32]    float32 \n",
            "synthesis.b32.torgb   264195      -        [8, 3, 32, 32]      float32 \n",
            "synthesis.b32:0       -           16       [8, 512, 32, 32]    float32 \n",
            "synthesis.b32:1       -           -        [8, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   2622465     4112     [8, 512, 64, 64]    float16 \n",
            "synthesis.b64.conv1   2622465     4112     [8, 512, 64, 64]    float16 \n",
            "synthesis.b64.torgb   264195      -        [8, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [8, 512, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [8, 512, 64, 64]    float32 \n",
            "synthesis.b128.conv0  1442561     16400    [8, 256, 128, 128]  float16 \n",
            "synthesis.b128.conv1  721409      16400    [8, 256, 128, 128]  float16 \n",
            "synthesis.b128.torgb  132099      -        [8, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [8, 256, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [8, 256, 128, 128]  float32 \n",
            "synthesis.b256.conv0  426369      65552    [8, 128, 256, 256]  float16 \n",
            "synthesis.b256.conv1  213249      65552    [8, 128, 256, 256]  float16 \n",
            "synthesis.b256.torgb  66051       -        [8, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [8, 128, 256, 256]  float16 \n",
            "synthesis.b256:1      -           -        [8, 128, 256, 256]  float32 \n",
            "synthesis.b512.conv0  139457      262160   [8, 64, 512, 512]   float16 \n",
            "synthesis.b512.conv1  69761       262160   [8, 64, 512, 512]   float16 \n",
            "synthesis.b512.torgb  33027       -        [8, 3, 512, 512]    float16 \n",
            "synthesis.b512:0      -           16       [8, 64, 512, 512]   float16 \n",
            "synthesis.b512:1      -           -        [8, 64, 512, 512]   float32 \n",
            "---                   ---         ---      ---                 ---     \n",
            "Total                 30276583    699904   -                   -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape        Datatype\n",
            "---            ---         ---      ---                 ---     \n",
            "b512.fromrgb   256         16       [8, 64, 512, 512]   float16 \n",
            "b512.skip      8192        16       [8, 128, 256, 256]  float16 \n",
            "b512.conv0     36928       16       [8, 64, 512, 512]   float16 \n",
            "b512.conv1     73856       16       [8, 128, 256, 256]  float16 \n",
            "b512           -           16       [8, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [8, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [8, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [8, 256, 128, 128]  float16 \n",
            "b256           -           16       [8, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [8, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [8, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [8, 512, 64, 64]    float16 \n",
            "b128           -           16       [8, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]    float16 \n",
            "b64            -           16       [8, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]    float32 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]    float32 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]    float32 \n",
            "b32            -           16       [8, 512, 16, 16]    float32 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]      float32 \n",
            "b16            -           16       [8, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]      float32 \n",
            "b8             -           16       [8, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [8, 512]            float32 \n",
            "b4.out         513         -        [8, 1]              float32 \n",
            "---            ---         ---      ---                 ---     \n",
            "Total          28982849    480      -                   -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.1      time 1m 54s       sec/tick 36.9    sec/kimg 577.32  maintenance 76.9   cpumem 5.51   gpumem 10.76  augment 2.000\n",
            "tick 1     kimg 4.1      time 19m 45s      sec/tick 1064.3  sec/kimg 263.95  maintenance 6.8    cpumem 5.86   gpumem 8.06   augment 1.964\n",
            "tick 2     kimg 8.1      time 37m 40s      sec/tick 1074.9  sec/kimg 266.60  maintenance 0.0    cpumem 5.82   gpumem 8.14   augment 1.936\n"
          ]
        }
      ],
      "source": [
        "!python train.py --gpus=1 --cfg=$config --metrics=None --outdir=$outdir --data=$dataset_path --snap=$snapshot_count --resume=$resume_from --augpipe=$augs --initstrength=$aug_strength --gamma=$gamma_value --mirror=$mirror_x --mirrory=$mirror_y --nkimg=$train_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgvSvfyi_R_-"
      },
      "source": [
        "### 恢复训练\n",
        "\n",
        "如果你的Colab训练到一半断开了，需要连上Colab后继续你的训练。主要需要修改两个参数，分别是 `resume_from` 和 `aug_strength` 。\n",
        "\n",
        "1. 将 `resume_from` 参数设置为最后的**.pkl**文件 (在 `results` 文件夹会看到，都是你训练出来的模型文件)。\n",
        "2. 更新 `aug_strength` 值。打开训练日志**log.txt**，查看前面.pkl文件对应的augment值，然后填上。\n",
        "\n",
        "设置完成后，继续执行训练。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VznRirOE5ENI"
      },
      "source": [
        "###Convert Legacy Model\n",
        "\n",
        "If you have an older version of a model (Tensorflow based StyleGAN, or Runway downloaded .pkl file) you’ll need to convert to the newest version. If you’ve trained in this notebook you do **not** need to use this cell.\n",
        "\n",
        "`--source`: path to model that you want to convert\n",
        "\n",
        "`--dest`: path and file name to convert to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzkP-Rww5Np9"
      },
      "outputs": [],
      "source": [
        "!python legacy.py --source=/content/drive/MyDrive/runway.pkl --dest=/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/runway.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6EtrPqL9ILk"
      },
      "source": [
        "##2.0 测试/推理 Testing/Inference\n",
        "\n",
        "测试、使用你的模型。一般用来生成图片和视频。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYdyfH0O8In_"
      },
      "source": [
        "### 2.1 生成单张图片\n",
        "\n",
        "`--network`: 你使用的.pkl文件路径。\n",
        "\n",
        "`--seeds`: 选择你的随机种子。不同的随机种子会得出不同的结果。\n",
        "\n",
        "`--truncation`: 截断, 用来截断你的潜在空间latent space。 一般来说，值越小，生成的照片就越“正常真实”（这里理解为结果接近你的数据集），但是多样性也会减少。一般使用0.5-1中间的值，实际上是无限制的数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYRXenMoZSHf"
      },
      "outputs": [],
      "source": [
        "network = '../../result/ukiyoe/00000-ukiyoe-1024-v2-pytorch-mirror-paper1024-gamma50-bg-resumecustom/network-snapshot-000016.pkl'\n",
        "outdir = '../../result/ukiyoe/generate-t1.5-016pkl'\n",
        "!python generate.py --outdir=$outdir --trunc=1.5 --seeds=0-200 --network=$network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_sGJowuPwwE"
      },
      "source": [
        "We can use these options for any image or video generation commands (excluding projection)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjOTCWVonoVL"
      },
      "source": [
        "### 2.2 遍历截断 Truncation Traversal\n",
        "\n",
        "下面你可以选择一个随机种子，然后看在该随机种子下，不同截断值之间会有什么变化。-1到1之间会有比较真实的图片，偏离越多图片就会越奇怪。\n",
        "#### 参数选项 Options \n",
        "`--network`: 你的.pkl文件。\n",
        "\n",
        "`--seeds`: 选择一个随机种子。\n",
        "\n",
        "`--start`: 初始截断值。\n",
        "\n",
        "`--stop`: 终止截断值，需要大于初始截断值，否则可能发生错误。\n",
        "\n",
        "`--increment`: 每一帧之间的变化大小。如果想要视频长一点，就设置小一点，反之亦然。(stop-start/increment=total frames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyzdGr7OnrMG"
      },
      "outputs": [],
      "source": [
        "!python generate.py --process=\"truncation\" --outdir=/content/out/trunc-trav-3/ --start=-0.8 --stop=0.8 --increment=0.02 --seeds=470 --network=/content/drive/MyDrive/stylegan2-transfer-models/mixed6k-network-snapshot-016470.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzj0igO8Lfu"
      },
      "source": [
        "### 2.3 插值 Interpolations\n",
        "\n",
        "插值是给一个向量产生非常小的变化的过程，可以用来做从一帧到另一帧的变化。\n",
        "Interpolation is the process of generating very small changes to a vector in order to make it appear animated from frame to frame.\n",
        "\n",
        "We’ll look at different examples of interpolation below.\n",
        "\n",
        "#### Options\n",
        "\n",
        "`--network`: 你的.pkl文件。\n",
        "\n",
        "`--interpolation`: 插值的类型。在z space和w space的区别。一般看不出区别。\n",
        "\n",
        "`--frames`: 帧数，控制视频长短。\n",
        "\n",
        "`--trunc`: 截断值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJSqafIzNwhx"
      },
      "source": [
        "#### 2.3.1 线性插值 Linear Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqkiskly8S5_"
      },
      "outputs": [],
      "source": [
        "!python generate.py --outdir=/content/out/video1-w-0.5/ --space=\"z\" --trunc=0.5 --process=\"interpolation\" --seeds=463,470 --network=/content/drive/MyDrive/stylegan2-transfer-models/mixed6k-network-snapshot-016470.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCUEV3aO8s_X"
      },
      "outputs": [],
      "source": [
        "!python generate.py --outdir=out/video1-w/ --space=\"w\" --trunc=1 --process=\"interpolation\" --seeds=85,265,297,849 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi3d7xzpN2Uj"
      },
      "source": [
        "####2.3.2 Slerp插值\n",
        "\n",
        "另外一种插值方式。从技术原理分析，线性插值在高维的GAN空间中并不是最好的。[This github link](https://github.com/soumith/dcgan.torch/issues/14) 有一些比较主流的观点和讨论。\n",
        "\n",
        "实际中找不出很大的区别。 (the difference in z- and w-space is enough in many cases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0-cUd3fB_kJ"
      },
      "outputs": [],
      "source": [
        "!python generate.py --outdir=out/slerp-z/ --space=\"z\" --trunc=1 --process=\"interpolation\" --interpolation=\"slerp\" --seeds=85,265,297,849 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl --frames=24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtnBIF75pcoY"
      },
      "outputs": [],
      "source": [
        "!python generate.py --outdir=out/slerp-w/ --space=\"w\" --trunc=1 --process=\"interpolation\" --interpolation=\"slerp\" --seeds=85,265,297,849 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl --frames=12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP1HsU_CPcF5"
      },
      "source": [
        "####2.3.3 噪声循环 Noise Loop\n",
        "\n",
        "在z space产生一个随机的插值视频（目前只适用于z space）。\n",
        "\n",
        "`--interpolation=\"noiseloop\"`: 设置好插值方式为noise loop。\n",
        "\n",
        "`--diameter`: “直径”。值越小，视频中展现出的图片多样性就越小；值越大，视频中展现出的图片多样性就越大。结合 `--frames` 可以帮助你调节视频的节奏。\n",
        "\n",
        "`--random_seed`: 决定你在z space的初始位置。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfR6DhfvN8b_"
      },
      "outputs": [],
      "source": [
        "!python generate.py --outdir=out/video-noiseloop-0.9d/ --trunc=0.8 --process=\"interpolation\" --interpolation=\"noiseloop\" --diameter=0.9 --random_seed=100 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkKFb-4CedOq"
      },
      "source": [
        "####2.3.4 回路循环 Circular Loop\n",
        "\n",
        "Noise Loop会比较杂乱，Circular相对平稳一点。\n",
        "\n",
        "作者建议用比较大的 `--diameter` （相对于Noise Loop所使用的）。比如50到500之间。\n",
        "\n",
        "`--frames` 可以控制速度和多样性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao62za9_QfOF"
      },
      "outputs": [],
      "source": [
        "!python generate.py --outdir=out/video-circularloop/ --trunc=1 --process=\"interpolation\" --interpolation=\"circularloop\" --diameter=800.00 --frames=720 --random_seed=90 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz-fVtzyAHg1"
      },
      "source": [
        "##3.0 投射 Projection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez7tXSpCA_zh"
      },
      "source": [
        "###3.1 基础投射 Basic Projector\n",
        "\n",
        "*   `--target`: 你的目标图片。模型会在自己的空间中“找到”这张图片（尽可能一致）。目标图片的大小必须和模型的图片大小一致。\n",
        "*   `--num-steps`: 步数。步数越大，找到相似度高的可能性就越高。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p84CtZUGAKnR"
      },
      "outputs": [],
      "source": [
        "!python projector.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80YTcjIQARWh"
      },
      "outputs": [],
      "source": [
        "!python projector.py --network=/content/drive/MyDrive/pretrained_model/abstract_art.pkl --outdir=/content/projector/ --target=/content/001-0.png --num-steps=200 --seed=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAxADbdpHHib"
      },
      "source": [
        "###3.2 Peter Baylies’ Projector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwS_ey9QF-nk"
      },
      "outputs": [],
      "source": [
        "!python /content/stylegan2-ada-pytorch/pbaylies_projector.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yj06MAABoLe"
      },
      "outputs": [],
      "source": [
        "!python /content/stylegan2-ada-pytorch/pbaylies_projector.py --network=/content/drive/MyDrive/pretrained_model/abstract_art.pkl --outdir=/content/projector-no-clip-006265-4-inv-3k/ --target-image=/content/001-0.png --num-steps=3000 --use-clip=False --use-center=False --seed=99"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "“Lecture4 StyleGAN2-ADA”的副本",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}